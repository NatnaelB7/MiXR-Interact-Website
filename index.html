<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="MiXR-Interact: Mixed Reality Interaction Dataset for Gaze, Hand, and Body">
  <meta name="keywords" content="MiXR-Interact">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MiXR-Interact: Mixed Reality Interaction Dataset for Gaze, Hand, and Body</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">MiXR-Interact: Mixed Reality Interaction Dataset for Gaze, Hand,
              and Body</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://www.iit.it/en-US/people-details/-/people/natnael-takele">Natnael Berhanu
                  Takele</a><sup>1,2</sup>,</span>
              <span class="author-block">
                <a href="https://www.iit.it/people-details/-/people/donatien-delehelle">Donatien
                  Delehelle</a><sup>1,2</sup>,</span>
              <span class="author-block">
                <a href="https://yaesolkim.github.io/">Yaesol
                  Kim</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://www.iit.it/it/people-details/-/people/yonas-tefera">Yonas Teodros
                  Tefera</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://www.nottingham.ac.uk/computerscience/people/nikhil.deshpande">Nikhil
                  Deshpande</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://www.iit.it/people-details/-/people/darwin-caldwell">Darwin
                  Caldwell</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://www.iit.it/it/people-details/-/people/jesus-ortiz">Jesus
                  Ortiz</a><sup>1</sup>and</span>
              <span class="author-block">
                <a href="https://rubrica.unige.it/personale/UkNDWV1r">Carmine
                  Recchiuto</a><sup>2</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Istituto Italiano di Tecnologia,</span>
              <span class="author-block"><sup>2</sup>University of Genova,</span>
              <span class="author-block"><sup>3</sup>University of Nottingham</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2410.05038"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
                <!-- Video Link. -->
                <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=NpEaa2P7qZI"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://drive.google.com/drive/folders/1NniCsN0xz71AxDFNI9TFyD5djv7o_1cd?usp=sharing"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>MiXR-Interact-Dataset</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video> -->
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">MiXR-Interact:</span> Mixed Reality Interaction Dataset for Gaze, Hand, and Body
        </h2>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              This paper presents MiXR-Interact, a dataset providing motion tracking data for
              users' interactions in mixed reality (MR) environments, focusing on tracking
              their gaze, upper body movements, and hand gestures.
            </p>
            <p>
              The dataset is based on the Meta Quest Pro headset, offering an easy-to-use resource
              for researchers and developers working in MR and human-computer interaction (HCI).
              MiXR-Interact focuses on collecting natural and precise interactions with virtual objects,
              with three core interaction types: pushing, pointing, and grasping. To ensure robustness
              and generalization, each interaction is performed across six distinct directions, reflecting
              a diverse range of movement trajectories relative to the user's body. This directional
              diversity provides critical insights into how users approach and engage with virtual objects from multiple
              angles. In addition, to precisely track contact points during interactions, 17 key contact points are
              defined for each direction and are labeled. These contact points are used as reference markers to
              accurately localize and quantify the joint-to-object contact points for each interaction type and
              direction.
            </p>
            <p>
              In addition to providing the dataset, this paper evaluates the quality and precision of the collected
              dataset in MR through a set of evaluation metrics. These metrics assess critical aspects of interaction
              performance, including Trajectory Similarity, Joint Orientation, and Joint-to-Contact Alignment. It also
              details the theoretical and implementation considerations for dataset collection, offering valuable
              insights for applications in MR and human-robot interaction (HRI).
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
      <!--/ Paper video. -->
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">

      <div class="columns has-text-centered">
        <div class="column">
          <div class="content">
            <h2 class="title is-4">Pushing Interaction</h2>
            <video id="dollyzoom" class="border-solid" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/pushing_ktk_video.webm" type="video/webm">
              Your browser doesn't seem to support the video tag.
            </video>
          </div>
        </div>
        <div class="column">
          <div class="content">
            <h2 class="title is-4">Pointing Interaction</h2>
            <video id="dollyzoom" class="border-solid" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/pointing_ktk_video.webm" type="video/webm">
              Your browser doesn't seem to support the video tag.
            </video>
          </div>

        </div>
        <div class="column">
          <div class="content">
            <h2 class="title is-4">Grasping Interaction</h2>
            <video id="dollyzoom" class="border-solid" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/grasping_ktk_video.webm" type="video/webm">
              Your browser doesn't seem to support the video tag.
            </video>
          </div>
        </div>
      </div>
      <!--/ Matting. -->

      <!-- Overview. -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Overview</h2>

          <div class="content has-text-justified">
            <p>Gaze, hand gestures, and full-body interaction are among the most essential and natural human
              communication and interaction modes. They often serve as powerful non-verbal cues, allowing us to perceive
              and interpret information even before it is verbally conveyed. These interaction methods are particularly
              critical in applications like Mixed Reality (MR), where creating an immersive experience demands a
              seamless and intuitive flow of information.
              MiXR-Interact provides a comprehensive dataset that captures body pose and eye tracking for immersive
              MR-based remote haptic teleoperation. The dataset is accompanied by methodologies for collecting
              and analyzing complex user interactions in MR environments, enabling advancements in MR, human-computer
              interaction, and human-robot collaboration.
            </p>
          </div>
          <div class="columns is-centered overview-image">
            <img src="./static/images/Body_Tracking_page-0001.jpg" class="overview-image" alt="Body Tracking Image" />
          </div>
          <div class="columns is-centered mt-2"><b>Human Body Pose and Joints</b></div>

          <h2 class="title is-3">Experiemental Setup</h2>
          <div class="content has-text-justified">
            <p>
              The system is built on the Meta Quest Pro MR headset, which supports gaze, hand, body tracking, and motion
              controllers. The MR interface, developed using Unreal Engine 5 (UE-5), includes 3D interaction elements.
              Participants interact with a virtual plane containing specific contact points that anchor 3D mesh objects
              tailored to each task.
              Spherical meshes are used for pointing tasks, offering intuitive and precise targets. Rectangular meshes,
              with their larger surface areas, are designed for pushing tasks, allowing natural application of force.
              Handle-shaped meshes, resembling door handles, are employed for grasping tasks, promoting realistic grip
              and hand poses.
            </p>
          </div>

          <div class="columns is-centered">
            <div class="column is-half">
              <img src="./static/images/SetupInteraction_page-0001.jpg" class="experimental-img"
                alt="Setup Interaction" />
            </div>
            <div class="column is-half">
              <img src="./static/images/SetupInteraction_2_page-0001.jpg" class="experimental-img"
                alt="Setup Interaction" />
            </div>
          </div>
          <br />
        </div>
      </div>
    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{takele2025mixr,
        title={MiXR-Interact: Mixed Reality Interaction Dataset for Gaze, Hand, and Body},
        author={Takele, Natnael Berhanu and Delehelle, Donatien and Kim, Yaesol and Tefera, Yonas Teodros and Deshpande, Nikhil and Caldwell, Darwin G and Ortiz, Jesus and Recchiuto, Carmine Tommaso},
        booktitle={HRI 2025 Workshop VAM-HRI}
        }</code></pre>
      <!--  </div> -->
      <!--</section> -->


      <footer class="footer">
        <div class="container">
          <div class="content has-text-centered">
            <!-- <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a> -->
            <a class="icon-link" href="https://github.com/NatnaelB7" class="external-link">
              <i class="fab fa-github"></i>
            </a>
          </div>
          <div class="columns is-centered">
            <div class="column is-8">
              <div class="content">
                <p>
                  The template of this website was borrowed from <a
                    href="https://github.com/nerfies/nerfies.github.io">nerfies</a>. Check them out !
                </p>
                <p>
                  This website is licensed under a <a rel="license"
                    href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                    Commons Attribution-ShareAlike 4.0 International License</a>.
                </p>
              </div>
            </div>
          </div>
        </div>
      </footer>

</body>

</html>